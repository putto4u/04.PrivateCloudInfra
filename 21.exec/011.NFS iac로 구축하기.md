이전 응답에서 설정해주신 강의 교재 형식과 개인별 맞춤 설정을 다시 한번 정교하게 반영하여, NFS 서버 구축을 위한 **IaC(Infrastructure as Code)** 가이드를 작성합니다.

이 과정은 수동 설정을 배제하고 **Ansible**과 **Terraform**을 결합하여 스토리지 인프라를 자동화하는 데 초점을 맞춥니다.

---

## NFS 스토리지 서버 자동 구축 및 K8s 연동

데이터의 영속성을 보장하기 위해 NFS(Network File System)를 구축합니다. 마스터 PC에서 앤서블을 통해 예비 서버(수강생 PC)를 NFS 서버로 만들거나, 별도의 스토리지 노드를 구성하는 자동화 시나리오입니다.

### 1. Ansible을 이용한 NFS 서버 구성 (Provisioning)

NFS 커널 서버 설치와 공유 디렉토리 권한 설정을 자동화하는 플레이북입니다.

```yaml
# nfs_server_setup.yml
# 설명: 지정된 서버에 NFS 서비스를 설치하고 k8s용 공유 폴더를 생성합니다.

- name: NFS 스토리지 서버 자동 구성
  hosts: storage_servers
  become: yes
  tasks:
    - name: 1. NFS 커널 서버 패키지 설치
      apt:
        name: nfs-kernel-server
        state: present
        update_cache: yes

    - name: 2. 공유 디렉토리 생성 (/srv/nfs/shared_data)
      file:
        path: /srv/nfs/shared_data
        state: directory
        mode: '0777' # 실습 편의를 위한 전권한 부여

    - name: 3. NFS 내보내기 설정 (Exports)
      lineinfile:
        path: /etc/exports
        line: "/srv/nfs/shared_data *(rw,sync,no_subtree_check,no_root_squash)"
        state: present

    - name: 4. 설정 적용 및 서비스 재시작
      shell: exportfs -ra
      notify: Restart NFS Service

  handlers:
    - name: Restart NFS Service
      service:
        name: nfs-kernel-server
        state: restarted
        enabled: yes

```

---

### 2. Terraform을 이용한 K8s 스토리지 리소스 정의 (Resource Management)

서버가 준비되면 Terraform의 [kubernetes provider](https://registry.terraform.io/providers/hashicorp/kubernetes/latest/docs)를 사용하여 PV와 PVC를 생성합니다.

```hcl
# storage.tf
# 설명: NFS 서버의 물리적 경로를 k8s 클러스터 내부의 논리적 자원으로 연결합니다.

# PersistentVolume (PV): 실제 저장 공간 정의
resource "kubernetes_persistent_volume" "nfs_pv" {
  metadata {
    name = "nfs-pv-storage"
  }
  spec {
    capacity = {
      storage = "10Gi"
    }
    access_modes = ["ReadWriteMany"] # 다수의 Pod가 동시 읽기/쓰기 가능
    persistent_volume_source {
      nfs {
        path   = "/srv/nfs/shared_data"
        server = "192.168.1.50" # Ansible로 구축한 서버 IP 입력
      }
    }
    storage_class_name = "nfs-manual"
  }
}

# PersistentVolumeClaim (PVC): 애플리케이션의 자원 요청
resource "kubernetes_persistent_volume_claim" "nfs_pvc" {
  metadata {
    name = "nfs-pvc-request"
  }
  spec {
    access_modes = ["ReadWriteMany"]
    resources {
      requests = {
        storage = "5Gi"
      }
    }
    storage_class_name = "nfs-manual"
  }
}

```

---

### 3. 작업 절차 및 실행 가이드

1. **Ansible 실행**: 인벤토리 파일(`hosts`)에 대상 IP를 기입한 후 플레이북을 실행하여 NFS 서버를 완성합니다.
* `ansible-playbook -i hosts nfs_server_setup.yml`


2. **Terraform 실행**: 정의된 스토리지를 k8s 클러스터에 배포합니다.
* `terraform init`
* `terraform apply`


3. **애플리케이션 연결**: 이전 챕터에서 만든 `backend-deployment`의 `volumes` 섹션에 `nfs-pvc-request`를 연결하여 데이터를 보존합니다.

---

### 4. 실무 전문가 팁 (Best Practices)

* **권한 보안**: `no_root_squash` 옵션은 클라이언트의 root 사용자를 서버의 root와 동일하게 대우하므로 보안에 취약할 수 있습니다. 운영 환경에서는 특정 UID/GID를 지정하여 매핑하는 방식을 권장합니다.
* **성능 고려**: NFS는 네트워크 상태에 따라 I/O 성능 편차가 큽니다. 데이터베이스 파일 저장용보다는 정적 미디어 파일이나 로그 공유용으로 적합합니다.
* **AWS 과금 주의**: AWS에서 실습 시, 직접 EC2에 NFS를 올리면 **EBS 볼륨 비용(GB당)**과 **EC2 인스턴스 비용**이 합산되어 발생합니다. 관리형 서비스인 **EFS**를 사용하면 IaC 관리가 더 편리하지만, 처리량(Throughput) 설정에 따라 추가 과금이 발생할 수 있으니 주의가 필요합니다.

Next Step: Helm을 이용한 NFS-Client-Provisioner 설치 및 동적 볼륨 자동 생성

---


Next Step: NFS 동적 프로비저닝 활용법
