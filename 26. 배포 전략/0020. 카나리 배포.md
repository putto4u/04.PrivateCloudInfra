# Module: Canary Deployment Strategy

## 1. 카나리 배포(Canary Deployment) 개요

카나리 배포는 **위험 완화(Risk Mitigation)**에 초점을 맞춘 배포 전략으로, 신규 버전을 전체 사용자에게 한 번에 배포하지 않고 **소규모의 트래픽(예: 1~5%)**만 먼저 분산시켜 운영 환경에서의 안정성을 검증한 뒤, 단계적으로 트래픽 비중을 늘려가는 방식이다.

이 용어는 과거 광부들이 유독 가스 누출을 감지하기 위해 가스에 민감한 카나리아 새를 먼저 광산에 들여보냈던 것에서 유래했다. IT 인프라에서는 소수의 사용자가 '카나리아' 역할을 하여 치명적인 버그나 성능 이슈를 조기에 발견하게 된다.

### 1.1 핵심 메커니즘

* **점진적 트래픽 전환(Gradual Rollout):** 100% 전환이 아닌 `95:5` -> `90:10` -> `50:50` -> `0:100` 순으로 점진적으로 구버전(Stable)에서 신버전(Canary)으로 트래픽을 이동시킨다.
* **실시간 검증(Validation):** 트래픽이 분산된 상태에서 로그, 에러율, Latency 등을 실시간으로 모니터링하여, 기준치(Threshold)를 넘는 에러 발생 시 즉시 트래픽을 차단하고 롤백한다.
* **A/B 테스트 가능:** 단순히 안정성 검증뿐만 아니라, 특정 사용자 그룹(예: 사내 직원, 베타 테스터)에게만 신규 기능을 노출하여 사용자 반응을 살피는 A/B 테스트 목적으로도 활용된다.

---

## 2. 구현 아키텍처 및 워크플로우

카나리 배포를 구현하기 위해서는 **정교한 라우팅 제어(Traffic Shaping)**가 가능한 로드밸런서나 프록시 서버가 필수적이다.

### 2.1 배포 단계 (Workflow)

1. **배포 준비:** 현재 운영 중인 버전(V1) 옆에 소규모의 신규 버전(V2) 인프라를 생성한다. (이 시점에는 트래픽 0%)
2. **초기 라우팅:** 로드밸런서 설정을 변경하여 전체 트래픽의 **5%**만 V2로 향하게 하고, 나머지 **95%**는 여전히 V1이 처리하도록 한다.
3. **검증(Verification):** V2로 유입된 트래픽에서 발생하는 HTTP 500 에러, 응답 속도 지연 등을 분석한다.
4. **확대(Scale Out):** 문제가 없으면 V2의 비중을 **10%, 30%, 50%**로 점차 늘린다. 이때 V2 파드(Pod)나 인스턴스 수를 오토스케일링(Auto Scaling)하여 부하를 감당하도록 한다.
5. **완료(Finalize):** 트래픽을 **100%** V2로 전환하고, 기존 V1 리소스를 제거하거나 축소하여 대기 상태로 만든다.

---

## 3. 플랫폼별 구현 전략 (AWS & Kubernetes)

### 3.1 AWS 환경에서의 구현

AWS는 관리형 서비스를 통해 가중치 기반 라우팅(Weighted Routing)을 지원한다.

* **Amazon Route 53 (DNS 레벨):**
* **가중치 기반 라우팅 정책(Weighted Routing Policy):** 동일한 도메인 이름에 대해 두 개의 레코드(Blue IP, Green IP)를 생성하고 가중치를 `255(기존):1(신규)` 등으로 설정하여 DNS 질의 응답 비율을 조절한다.
* *주의:* DNS 캐싱(TTL) 문제로 인해 즉각적인 트래픽 제어가 어려울 수 있다.


* **Application Load Balancer (ALB):**
* **리스너 규칙(Listener Rule):** 하나의 리스너 아래에 두 개의 대상 그룹(Target Group)을 연결하고, 트래픽 분배 가중치(Forward to)를 설정할 수 있다. (예: Target Group A: 90%, Target Group B: 10%)
* *비용:* 배포가 진행되는 동안 두 버전의 인스턴스가 동시에 실행되므로, EC2 및 RDS 리소스 비용이 중복 발생한다.


* **AWS App Mesh / API Gateway:**
* 마이크로서비스 환경에서는 서비스 메시(Service Mesh) 레벨에서 정교한 트래픽 제어가 가능하다.



### 3.2 Kubernetes(K8s) 환경에서의 구현

Kubernetes 기본 객체만으로는 정교한 가중치 조절이 어렵기 때문에, **Ingress Controller**나 **Service Mesh**를 활용한다.

* **Nginx Ingress Controller:**
* `nginx.ingress.kubernetes.io/canary: "true"`
* `nginx.ingress.kubernetes.io/canary-weight: "10"`
* 위와 같은 **Annotation**을 사용하여 특정 Ingress 리소스를 카나리용으로 지정하면, 전체 트래픽의 10%만 해당 서비스로 라우팅된다.


* **Istio (Service Mesh):**
* `VirtualService` 리소스를 정의하여 `weight` 속성을 통해 트래픽을 백분율로 정밀하게 제어할 수 있다.


* **Argo Rollouts:**
* Kubernetes의 표준 `Deployment` 대신 `Rollout` 리소스를 사용하여, "5% 오픈 -> 10분 대기 -> 승인 -> 20% 오픈"과 같은 파이프라인을 자동화한다.



---

## 4. 장점과 단점 (Trade-offs)

### 4.1 장점 (Pros)

* **실운영 환경 검증(Production Testing):** 스테이징 환경에서는 발견할 수 없는, 실제 사용자 트래픽과 데이터 패턴에 따른 이슈를 파악할 수 있다.
* **무중단 및 빠른 롤백:** 이슈 발생 시 트래픽 가중치를 0으로 변경하면 즉시 롤백이 가능하며, 사용자 영향도를 최소화(전체의 1~5%만 영향)할 수 있다.
* **리소스 효율성:** 블루-그린 배포처럼 전체 인프라를 두 배로 복제할 필요 없이, 소규모 리소스로 시작하여 점진적으로 늘리므로 비용 효율적이다.

### 4.2 단점 (Cons)

* **구현 복잡도:** 트래픽을 정교하게 제어하고 모니터링해야 하므로, 라우팅 로직과 자동화 파이프라인 구성이 복잡하다.
* **배포 시간 지연:** 단계별로 검증하고 트래픽을 늘려야 하므로, 전체 배포 완료까지 걸리는 시간이 롤링 배포나 블루-그린 배포보다 길다.
* **버전 호환성:** 두 버전의 애플리케이션이 동시에 운영되므로, 데이터베이스 스키마나 API 포맷의 하위 호환성 유지가 필수적이다.

---

## 5. 비교 요약: Rolling vs Blue-Green vs Canary

| 특징 | 롤링 배포 (Rolling) | 블루-그린 (Blue-Green) | 카나리 (Canary) |
| --- | --- | --- | --- |
| **배포 방식** | 서버를 하나씩 순차적으로 교체 | 신규 환경 전체 구축 후 한 번에 스위칭 | 소량의 트래픽만 신규 환경으로 분산 |
| **롤백 속도** | 느림 (역순으로 재배포 필요) | **매우 빠름** (스위치만 원복) | **매우 빠름** (트래픽 차단) |
| **리스크** | 중간 (배포 중 일부 사용자 영향) | 낮음 (테스트 후 전환, 단 전환 실패 시 전체 영향) | **가장 낮음** (소수 사용자만 영향) |
| **리소스 비용** | 낮음 (기존 리소스 활용) | **높음** (전체 리소스 2배 필요) | 중간 (신규 버전만큼만 추가) |
| **사용 사례** | 일반적인 서비스 업데이트 | 메이저 버전 업데이트, 무중단 필수 | 중요 기능 변경, 리스크 최소화 필수 |

**전문가 팁:**
AWS나 Kubernetes 환경에서 카나리 배포를 수행할 때는 반드시 **Metric Server**나 **Prometheus**와 연동된 자동화 도구(예: Spinnaker, Argo Rollouts)를 사용하여, 사람의 개입 없이 에러율 증가 시 자동으로 롤백되도록 구성하는 것이 모범 사례(Best Practice)이다.

Next Step: Ingress Controller와 Service Mesh(Istio)의 개념 및 차이점
