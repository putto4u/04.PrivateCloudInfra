# 챕터 8. 매트릭 모니터링 시스템 구축 및 운영 전략

쿠버네티스 환경에서 모니터링 시스템을 구축하는 가장 표준적이고 효율적인 방법은 **헬름(Helm)** 패키지 매니저를 사용하는 것입니다. 수십 개의 YAML 파일을 직접 관리하는 대신, 검증된 커뮤니티 차트인 `kube-prometheus-stack`을 사용하여 프로메테우스, 그라파나, 노드 익스포터, 얼럿매니저를 통합 배포하고 운영하는 방법을 다룹니다.

---

## 1. 헬름(Helm) 기반 설치 준비

실무에서는 개별 구성요소를 따로 설치하지 않고, **`kube-prometheus-stack`**이라는 올인원(All-in-One) 차트를 사용합니다. 이 차트는 모니터링에 필요한 모든 구성요소와 기본 설정, 대시보드 템플릿까지 포함하고 있습니다.

### 1.1. 저장소(Repository) 추가

가장 먼저 헬름 차트 저장소를 로컬 환경에 등록해야 합니다.

```bash
# 프로메테우스 커뮤니티 공식 저장소 추가
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts

# 저장소 정보 최신화
helm repo update 

```

### 1.2. 네임스페이스 격리

모니터링 리소스는 시스템의 핵심이므로, 일반 애플리케이션과 섞이지 않도록 별도의 네임스페이스(Namespace)에 격리하여 설치합니다.

```bash
kubectl create namespace monitoring

```

---

## 2. 운영 환경을 고려한 설정 커스터마이징 (values.yaml)

기본 설정(`values.yaml`) 그대로 설치하면 데이터가 보존되지 않거나 리소스 낭비가 발생할 수 있습니다. 운영 환경에 맞게 필수 설정을 재정의해야 합니다.

### 2.1. 주요 설정 포인트

| 설정 항목 | 설명 | 권장 설정 (실습/소규모 운영) |
| --- | --- | --- |
| **retention** | 데이터 보관 주기 | 기본 10일  **3일 ~ 5일** (디스크 용량 절약) |
| **storageClass** | 데이터 영구 저장소 | **gp2 (AWS)** 또는 **local-path (On-premise)** 지정 필수 |
| **service.type** | 그라파나 접근 방식 | ClusterIP  **NodePort** 또는 **LoadBalancer** |
| **adminPassword** | 그라파나 접속 암호 | 초기 비밀번호 설정 (보안 권장) |

### 2.2. 커스텀 설정 파일 작성 (`my-values.yaml`)

```yaml
# my-values.yaml 예시
#스토리지를 쓸 경우 : 프로메테우스 설정을 넣고. 안쓸경우 생략
prometheus:
  prometheusSpec:
    # 데이터 보관 주기 설정 (디스크 용량 고려)
    retention: 3d
    # 영구 저장소(PVC) 설정: 파드가 재시작되어도 데이터 보존
    storageSpec:
      volumeClaimTemplate:
        spec:
          storageClassName: gp2  # 환경에 맞는 스토리지 클래스명 입력
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 10Gi

# 그라파나는 필수(GUI 사용)
grafana:
  # 외부 접속을 위해 NodePort 혹은 LoadBalancer로 변경
  service:
    type: NodePort
    nodePort: 30000  # 고정 포트 사용 시 (선택 사항)
  # 초기 관리자 비밀번호 설정
  adminPassword: "admin"

```

---

## 3. 설치 및 배포 검증

작성한 설정 파일을 기반으로 클러스터에 배포를 진행합니다.

### 3.1. 배포 명령어

```bash
helm install prometheus-stack prometheus-community/kube-prometheus-stack \
  -f my-values.yaml \
  --namespace monitoring

또는 스토리지를 안쓸때 
helm install prometheus-stack prometheus-community/kube-prometheus-stack \
  -f my-values.yaml \
  --namespace monitoring \
  --set prometheus.prometheusSpec.storageSpec.emptyDir.medium="" \
  --set alertmanager.alertmanagerSpec.storageSpec.emptyDir.medium="" \
  --set grafana.persistence.enabled=false
```

### 3.2. 설치 확인

설치 후 몇 분 뒤, 다음 명령어로 모든 파드(Pod)가 `Running` 상태인지 확인합니다.

```bash
kubectl get pods -n monitoring

```

* **prometheus-0:** 메인 서버 파드 (StatefulSet)
* **grafana-xx:** 시각화 도구 파드
* **node-exporter-xx:** 각 노드마다 1개씩 실행되는 데몬셋

---

## 4. 운영 및 접속 방법

설치가 완료되면 실제로 그라파나 대시보드에 접속하여 데이터가 수집되는지 확인해야 합니다.

### 4.1. 그라파나 대시보드 접속

`my-values.yaml`에서 `NodePort`로 설정했다면, 워커 노드의 IP와 지정된 포트로 접속할 수 있습니다.

* **접속 주소:** `http://<Worker-Node-IP>:30000`
* **계정:** `admin` / `admin` (설정 파일에서 지정한 비밀번호)

### 4.2. 포트 포워딩(Port-Forwarding)을 이용한 임시 접속

`Service` 타입을 변경하지 않았다면, `kubectl`의 포트 포워딩 기능을 사용하여 로컬 PC에서 접속할 수 있습니다.

```bash
# 로컬 8080 포트를 그라파나 80 포트로 연결
kubectl port-forward svc/prometheus-stack-grafana 8080:80 -n monitoring

```

이후 브라우저에서 `localhost:8080`으로 접속합니다.

---

## 5. 아키텍트의 운영 조언 (Operation Tips)

성공적인 모니터링 시스템 운영을 위해 다음 3가지를 반드시 기억해야 합니다.

1. **데이터 영속성(Persistence) 확보:**
* 프로메테우스 파드는 업데이트나 장애로 언제든지 재시작될 수 있습니다. `StorageClass`를 통한 PV(Persistent Volume) 연결 없이는 재시작 시 **모든 과거 데이터가 날아갑니다.** 반드시 PVC 설정을 확인하십시오.


2. **설정 변경은 파일로 관리 (GitOps):**
* 운영 중 설정을 바꿀 때 `kubectl edit` 명령어로 라이브(Live) 상태를 직접 수정하지 마십시오. 반드시 `my-values.yaml` 파일을 수정한 후 `helm upgrade` 명령어로 반영해야 이력을 추적할 수 있습니다.


3. **리소스 모니터링의 모니터링:**
* 프로메테우스 자체도 메모리를 많이 사용하는 애플리케이션입니다. 모니터링 시스템이 죽으면 장애 알림을 받을 수 없으므로, 프로메테우스 파드의 리소스 사용량(Memory Usage)을 주기적으로 체크하고 필요시 `Limit`을 늘려주어야 합니다.



---

# 챕터 9. 매트릭 수집기(Exporter)의 자동 설치와 구성





## 1. 헬름 차트가 자동으로 설치하는 구성요소

`helm install` 명령어를 실행하면, 프로메테우스 서버와 함께 다음 두 가지 핵심 수집기가 자동으로 클러스터에 배포됩니다.

### 1.1. 노드 익스포터 (Node Exporter)

* **역할:** 물리적 하드웨어(노드)의 상태를 측정합니다.
* **수집 데이터:** CPU 사용률, 메모리 잔량, 디스크 I/O, 네트워크 트래픽 등.
* **배포 방식:** **데몬셋(DaemonSet)** 형태로 배포되어, 클러스터에 노드가 추가될 때마다 자동으로 해당 노드에 설치됩니다. (챕터 6에서 다룬 내용이 자동으로 구현됨)

### 1.2. 쿠브 스테이트 매트릭 (Kube State Metrics)

* **역할:** 쿠버네티스 논리적 객체(Object)들의 상태를 측정합니다.
* **수집 데이터:** 파드(Pod)의 상태(Running, Failed 등), 디플로이먼트(Deployment)의 레플리카 개수, 서비스(Service) 상태 등.
* **배포 방식:** **디플로이먼트(Deployment)** 형태로 배포되어, 쿠버네티스 API 서버와 통신하며 데이터를 수집합니다.

---

## 2. 설치 확인 및 검증 (Verification)

실제로 매트릭 수집기가 잘 설치되었는지 확인하는 절차입니다. 터미널에서 다음 명령어를 입력하여 파드 목록을 확인합니다.

```bash
kubectl get pods -n monitoring

```

**[출력 예시 및 분석]**

| 파드 이름 (Prefix) | 상태 | 설명 |
| --- | --- | --- |
| `prometheus-node-exporter-xyz` | **Running** | 각 노드마다 1개씩 실행 중이어야 합니다. (노드가 3개라면 3개가 보임) |
| `kube-state-metrics-abcde` | **Running** | 클러스터 전체 상태를 담당하므로 보통 1개가 실행됩니다. |
| `prometheus-server-0` | **Running** | 수집된 데이터를 저장하는 메인 서버입니다. |
| `grafana-12345` | **Running** | 데이터를 시각화하는 도구입니다. |

> **확인 포인트:**
> 만약 `node-exporter` 파드의 개수가 현재 운영 중인 워커 노드의 개수와 일치한다면, 하드웨어 매트릭 수집 준비가 완벽하게 끝난 것입니다.

---

## 3. 매트릭 데이터 흐름 (Data Flow)

설치가 완료되면 시스템 내부에서는 다음과 같은 흐름으로 매트릭이 수집됩니다.

1. **생성:** `Node Exporter`와 `Kube State Metrics`가 실시간으로 매트릭 데이터를 생성하여 자신의 HTTP 엔드포인트(`/metrics`)에 노출합니다.
2. **수집 (Scrape):** `Prometheus Server`가 설정된 주기(기본 1분)마다 이 엔드포인트에 접속하여 데이터를 긁어갑니다(Pull).
3. **저장:** 긁어온 데이터는 프로메테우스 내부의 시계열 데이터베이스(TSDB)에 저장됩니다.
4. **조회:** 사용자가 `Grafana` 대시보드를 열면, 그라파나가 프로메테우스 DB에 쿼리(PromQL)를 날려 그래프를 그립니다.

---

## 4. 아키텍트의 주의사항 (Architect's Note)

### '매트릭스 서버(Metrics Server)'와의 혼동 주의

쿠버네티스에는 `metrics-server`라는 또 다른 구성요소가 있습니다. 이는 주로 `kubectl top` 명령어를 쓰거나 HPA(오토스케일링)를 할 때 사용됩니다.

* `kube-prometheus-stack`은 모니터링 전용이므로, `metrics-server`와는 별개입니다.
* 하지만 대부분의 헬름 차트는 `metrics-server`가 없어도 프로메테우스만으로 충분히 모니터링이 가능하도록 구성되어 있습니다.
* (참고: `kubectl top` 명령어가 안 먹힌다면 `metrics-server`를 따로 설치해야 하지만, 그라파나 모니터링에는 지장이 없습니다.)

---

**Next Step:** 수집된 데이터가 정상적인지 확인하기 위한 프로메테우스 웹 UI 접속 및 상태 타겟(Target) 확인 실습


---
현재 상황은 이전 설치 시 생성되었던 **StatefulSet의 잔재와 PVC(Persistent Volume Claim)**가 클러스터에 남아있어, 새로 설치한 설정과 충돌하거나 이전의 잘못된 스토리지 설정(`m_stcm`)을 계속 참조하려고 시도하기 때문에 발생합니다.

쿠버네티스에서 Helm을 지워도 `PVC`와 `CustomResourceDefinition(CRD)`은 자동으로 삭제되지 않는 경우가 많습니다. "완전 초기화 후 재설치"를 위한 클리닝 절차를 안내해 드립니다.

---

## 1. 기존 설치 잔해 완전 제거 (Purge)

단순히 `helm uninstall`만으로는 부족합니다. 아래 순서대로 강제 삭제를 진행하십시오.

### Step 1: Helm 삭제

```bash
helm uninstall prometheus-stack -n monitoring

```

### Step 2: 남아있는 리소스 강제 삭제 (핵심)

설정을 '스토리지 없음'으로 바꿨음에도 로그에 스토리지 에러가 보이는 이유는 기존에 생성된 **StatefulSet**과 **PVC**가 삭제되지 않았기 때문입니다.

```bash
# Prometheus와 Alertmanager 관련 StatefulSet 삭제
kubectl delete statefulset -l app.kubernetes.io/instance=prometheus-stack -n monitoring

# 남아있는 모든 PVC 삭제 (데이터가 초기화되니 주의하세요)
kubectl delete pvc -l app.kubernetes.io/instance=prometheus-stack -n monitoring

```

### Step 3: CRD(Custom Resource Definition) 정리

Operator 방식은 CRD를 사용하므로, 이 정보가 꼬이면 재설치 시 이전 설정을 다시 불러올 수 있습니다.

```bash
# Prometheus 관련 CRD 목록 확인 및 삭제
kubectl get crd | grep coreos.com | awk '{print $1}' | xargs kubectl delete crd

```

---

## 2. 깨끗한 환경에서 재설치 (스토리지 제외 설정)

용량 문제나 스토리지 클래스 설정이 번거롭다면, **Persistence(영속성) 기능을 완전히 끄고** 실행 성능 위주로 먼저 올리는 것이 방법입니다. `m_stcm` 에러를 피하기 위한 설정입니다.

### `values.yaml` 수정 또는 명령행 주입

아래 명령어를 통해 스토리지 사용을 명시적으로 비활성화하고 재설치합니다.

```bash
helm install prometheus-stack prometheus-community/kube-prometheus-stack \
  --namespace monitoring \
  --create-namespace \
  --set prometheus.prometheusSpec.storageSpec={} \
  --set alertmanager.alertmanagerSpec.storage={} \
  --set grafana.persistence.enabled=false

```

---

## 3. 실전 체크리스트 (전문가 팁)

* **Evicted Pod 확인**: 용량 부족으로 인해 이전에 `Evicted` 된 포드들이 남아있는지 확인하세요. `kubectl get pods -A | grep Evicted` 후 있다면 삭제해줘야 합니다.
* **Finalizers 제거**: 만약 리소스가 `Terminating` 상태에서 멈춰있다면, 아래 명령어로 강제 종료 시키세요.
```bash
kubectl patch pvc <pvc-name> -n monitoring -p '{"metadata":{"finalizers":null}}' --type=merge

```



---

> [!IMPORTANT]
> **AWS 과금 주의**: 만약 이 과정에서 EBS 등 외부 스토리지를 동적으로 생성하는 StorageClass를 사용하게 된다면, 미사용 PV가 남아 과금이 발생할 수 있습니다. `kubectl get pv`를 수시로 확인하여 연결되지 않은(Released) 볼륨은 클라우드 콘솔에서 삭제 확인이 필요합니다.

Next Step: 클리닝 작업 후 리소스 삭제 여부 확인 및 재설치 결과 모니터링

안내해 드린 대로 완전히 밀어낸 뒤 다시 시도해 보시고, 여전히 이전 로그 메시지가 보인다면 어느 단계에서 리소스가 남아있는지 다시 짚어보겠습니다.
