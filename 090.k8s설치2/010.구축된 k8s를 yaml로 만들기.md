기존에 구축된 Kubernetes 마스터 노드(Control Plane)의 설정과 상태를 그대로 복제하여 두 번째 마스터 노드를 구성하거나, 전체 클러스터 상태를 코드화(IaC)하기 위해 YAML 파일을 추출하는 방법입니다.

단순히 `kubectl get -o yaml`을 사용하는 것을 넘어, 클러스터의 핵심 설정과 인증서, 정적 포드(Static Pods) 설정을 모두 확보해야 합니다.

---

## 1. 쿠버네티스 객체 정보 추출 (API 리소스)

클러스터 내에 정의된 모든 리소스(Deployments, Services, ConfigMaps 등)를 YAML로 백업합니다.

### **모든 리소스 일괄 추출 스크립트**

특정 네임스페이스나 전체 클러스터의 리소스를 개별 YAML 파일로 저장하는 방식입니다.

```bash
# 모든 네임스페이스의 주요 리소스 추출
for n in $(kubectl get -o name namespaces); do
  mkdir -p backup/${n}
  kubectl get -o yaml --export $n > backup/${n}/all-resources.yaml
done

```

> [!TIP] **추천 도구: velero 또는 k8s-backup**
> 수동 추출보다는 **Velero** 같은 전문 백엔드 백업 도구를 사용하여 스냅샷을 찍는 것이 온프레미스 환경에서 훨씬 안전합니다.

---

## 2. 컨트롤 플레인 핵심 설정 파일 복사

마스터 노드의 심장부인 `/etc/kubernetes/` 디렉토리의 파일들을 확보해야 합니다. 이는 YAML 기반으로 동작하는 정적 포드들의 정의서입니다.

* **경로:** `/etc/kubernetes/manifests/`
* **대상 파일:**
* `kube-apiserver.yaml`
* `kube-controller-manager.yaml`
* `kube-scheduler.yaml`
* `etcd.yaml`



이 파일들을 복사하여 마스터 2번의 동일 경로에 넣으면, `kubelet`이 이를 감지하여 컨트롤 플레인 컴포넌트들을 자동으로 실행합니다.

---

## 3. Kubeadm 설정 정보 추출

`kubeadm`으로 설치했다면, 클러스터 초기화 시 사용된 설정(ClusterConfiguration)을 YAML로 다시 뽑아낼 수 있습니다. 이 정보는 마스터 2번을 조인(Join)시킬 때 매우 중요합니다.

```bash
# 현재 실행 중인 클러스터의 kubeadm 설정 추출
kubectl -n kube-system get configmap kubeadm-config -o jsonpath='{.data.ClusterConfiguration}' > kubeadm-config.yaml

```

---

## 4. 인증서 및 토큰 관리 (핵심 작업)

마스터 노드를 추가할 때는 YAML 파일뿐만 아니라 **인증서(CA)** 공유가 필수적입니다.

* **인증서 위치:** `/etc/kubernetes/pki/`
* **공유 필수 파일:** `ca.crt`, `ca.key`, `sa.key`, `sa.pub` 등 (모든 pki 디렉토리 복사 권장)
* **조인 토큰 생성:**
```bash
# 마스터 노드 추가를 위한 조인 커맨드와 인증서 키 생성
kubeadm token create --print-join-command --certificate-key $(kubeadm init phase upload-certs --upload-certs | tail -1)

```



---

## 5. 전체 작업 체크리스트 (Summary)

| 단계 | 작업 내용 | 비고 |
| --- | --- | --- |
| **1. Config 추출** | `kubeadm-config`를 YAML로 저장 | 클러스터 설정 일관성 유지 |
| **2. Manifest 복사** | `/etc/kubernetes/manifests` 내 YAML 복사 | 정적 포드 실행용 |
| **3. PKI 복사** | `/etc/kubernetes/pki` 내 인증서 전체 복사 | 보안 컨텍스트 유지 |
| **4. 인프라 설정** | `/etc/cni/net.d` 네트워크 설정 복사 | CNI 플러그인 동기화 |

---

> [!CAUTION] **중복 및 충돌 주의 (과금/리소스)**
> * **IP 주소:** YAML 내에 특정 IP(예: `advertise-address`)가 하드코딩되어 있다면 마스터 2번의 IP로 반드시 수정해야 합니다.
> * **로드밸런서 비용:** 온프레미스에서 마스터를 다중화(HA)할 경우, 상단에 **Keepalived**나 **HAProxy** 같은 가상 IP(VIP) 장치가 필수입니다. AWS 등 클라우드 환경이라면 NLB/ALB 사용에 따른 추가 과금이 발생합니다.
> 
> 

Next Step: **kubeadm을 이용한 마스터 노드 Join 커맨드 실행** 혹은 **Keepalived를 이용한 VIP 설정**

---
기존 마스터(Master 1)에서 추출한 설정과 인증서를 바탕으로 **Master 2**를 추가하여 고가용성(HA) 제어 평면을 구축하는 실무 과정을 설명합니다.

이 과정은 `kubeadm`의 **Join** 기능을 사용하며, 온프레미스 환경에서 `nerdctl`과 `containerd`가 사전 설치되어 있어야 합니다.

---

## 1. Master 2 추가를 위한 사전 준비

Master 2 노드에 접속하여 아래 명령들을 실행합니다.

### **인증서 및 설정 파일 복사 (Master 1 → Master 2)**

Master 1의 인증서가 없으면 Master 2는 클러스터의 일원으로 인정받지 못합니다. (Master 1에서 실행)

```bash
# Master 1의 인증서를 Master 2로 안전하게 복사합니다.
# /etc/kubernetes/pki 내의 모든 파일을 Master 2의 동일 경로로 복사해야 합니다.
sudo scp -r /etc/kubernetes/pki <Master2_IP>:/etc/kubernetes/

```

---

## 2. Master 2 조인(Join) 실행 명령

Master 1에서 생성한 **Certificate Key**와 **Token**을 사용하여 Master 2를 제어 평면으로 등록합니다.

```bash
# 아래 명령은 Master 1에서 실행하여 조인 커맨드를 생성한 뒤, Master 2에서 실행합니다.
sudo kubeadm join <MASTER_VIP_OR_IP>:6443 \
    --token <token_value> \ # 클러스터 접근을 위한 일회성 보안 토큰
    --discovery-token-ca-cert-hash sha256:<hash_value> \ # 서버 인증서 유효성 검증용 해시
    --control-plane \ # 이 노드를 워커가 아닌 '마스터(제어 평면)'로 지정
    --certificate-key <cert_key_value> # Master 1에서 업로드된 인증서를 내려받기 위한 키

```

---

## 3. 마스터 노드 복구 및 설정 (YAML 적용)

추출했던 YAML 파일들을 Master 2 환경에 맞게 적용하고 확인하는 과정입니다.

### **Kubeconfig 설정 (Master 2에서 실행)**

관리자 권한으로 `kubectl`을 사용할 수 있도록 환경 변수를 설정합니다.

```bash
mkdir -p $HOME/.kube # 사용자 홈 디렉토리에 .kube 폴더 생성
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config # 관리자 설정 파일을 복사
sudo chown $(id -u):$(id -g) $HOME/.kube/config # 현재 사용자에게 파일 소유권 부여

```

### **정적 포드(Static Pod) 상태 확인**

`/etc/kubernetes/manifests`에 복사된 YAML들에 의해 컨테이너들이 `nerdctl` 상에서 잘 도느지 확인합니다.

```bash
# nerdctl로 k8s.io 네임스페이스 내의 실행 중인 컨테이너 확인
sudo nerdctl -n k8s.io ps | grep -E 'api|controller|scheduler|etcd'

```

---

## 4. 설치 스크립트 상세 분석 (주석 포함)

Master 2를 구성하는 핵심 로직을 담은 가상의 자동화 쉘 스크립트 예시입니다.

```bash
#!/bin/bash

# 1. containerd 서비스가 활성화되어 있는지 확인합니다.
sudo systemctl enable --now containerd

# 2. 마스터 노드 전용 IP와 포트(6443)가 열려있는지 확인합니다. (방화벽 설정)
sudo ufw allow 6443/tcp comment 'Kubernetes API Server'

# 3. kubeadm join 명령을 수행하여 클러스터에 제어 평면으로 합류합니다.
# 이 과정에서 /etc/kubernetes/manifests/ 내에 API 서버 등의 YAML이 자동 생성됩니다.
sudo kubeadm join 192.168.0.10:6443 \
    --token abcdef.1234567890abcdef \ # 인증 토큰
    --discovery-token-ca-cert-hash sha256:7d... \ # CA 인증서 해시값
    --control-plane \ # 제어 평면 역할 부여
    --certificate-key e4... # 복사한 인증서를 복호화할 키

# 4. 노드 상태가 'Ready'가 될 때까지 기다립니다.
watch kubectl get nodes

```

---

> [!CAUTION] **온프레미스 HA 구성 시 주의사항**
> * **Load Balancer:** 마스터가 2대 이상일 경우, 외부에서는 하나의 IP(VIP)로 접근해야 합니다. **Keepalived**나 **HAProxy**를 설정하지 않고 각 마스터의 개별 IP로 조인하면, Master 1 장애 시 Master 2가 제 역할을 하지 못할 수 있습니다.
> * **etcd 동기화:** 마스터 2번이 추가되면 내장된 etcd 데이터베이스가 자동으로 동기화됩니다. 이때 네트워크 대역폭 소모가 발생하며, 디스크 I/O 속도가 느릴 경우 클러스터 전체가 불안정해질 수 있습니다.
> 
> 

Next Step: **Keepalived를 이용한 가상 IP(VIP) 설정** 혹은 **HAProxy 로드밸런싱 구성**

---

**[강의 교재 체크리스트]**

* [x] `nerdctl`을 통한 컨테이너 상태 확인 명령 포함
* [x] 단계별 명령어에 대한 상세 주석 및 설명 제공
* [x] 다중 마스터 구성 시 필수적인 LB(로드밸런서) 과금/설정 주의사항 명시
* [x] 전문가용 톤 유지 및 가독성 높은 마크다운 적용
* [x] Next Step 핵심 단어 제시 (참고: [Kubernetes HA topology](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/ha-topology/))
